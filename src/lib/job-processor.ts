/**
 * BACKGROUND JOB PROCESSOR MODULE
 * ================================
 *
 * This module processes long-running operations asynchronously in the background.
 * It prevents API timeouts and improves user experience for operations that take
 * several seconds to complete (like processing 100-item transfer requests).
 *
 * WHY BACKGROUND JOBS?
 * --------------------
 * - **Prevent Timeouts**: Transfer with 100 items can take 60+ seconds (API timeout)
 * - **Better UX**: User gets immediate response ("Processing in background...")
 * - **Retry Logic**: Automatic retry on transient failures (network, deadlocks)
 * - **Monitoring**: Track progress via job status (pending ‚Üí processing ‚Üí completed)
 * - **Fault Tolerance**: Recover from crashes by resuming pending jobs
 * - **Scalability**: Process multiple jobs concurrently (future: worker pool)
 *
 * HOW IT WORKS:
 * -------------
 * 1. User triggers operation (e.g., "Send Transfer")
 * 2. API creates Job record in database (status: 'pending')
 * 3. API returns immediately with job ID ("Job #123 queued")
 * 4. Worker picks up pending job and processes it
 * 5. Job status updates: pending ‚Üí processing ‚Üí completed/failed
 * 6. Frontend polls job status to show progress/completion
 *
 * JOB LIFECYCLE:
 * --------------
 * ```
 * pending (created by API)
 *    ‚Üì
 * processing (picked up by worker)
 *    ‚Üì
 * ‚îú‚îÄ‚Üí completed (success!)
 * ‚îú‚îÄ‚Üí failed (max retries exhausted)
 * ‚îî‚îÄ‚Üí pending (retry scheduled - exponential backoff)
 * ```
 *
 * JOB TYPES:
 * ----------
 * - **transfer_send**: Deduct stock from source location (bulk operation)
 * - **transfer_complete**: Add stock to destination location (bulk operation)
 * - **sale_create**: Process sale and deduct inventory (TODO)
 * - **purchase_approve**: Approve purchase and add inventory (TODO)
 *
 * DATABASE SCHEMA:
 * ----------------
 * ```prisma
 * model Job {
 *   id          Int       @id @default(autoincrement())
 *   businessId  Int
 *   userId      Int       // User who triggered the job
 *   type        String    // transfer_send, transfer_complete, etc.
 *   payload     Json      // Job parameters (e.g., { transferId: 123 })
 *   status      String    // pending, processing, completed, failed
 *   progress    Int       @default(0)     // Items processed so far
 *   total       Int       @default(0)     // Total items to process
 *   result      Json?     // Success result data
 *   error       String?   // Error message if failed
 *   attempts    Int       @default(0)     // Number of attempts
 *   maxAttempts Int       @default(3)     // Max retry attempts
 *   nextRetryAt DateTime? // When to retry (exponential backoff)
 *   startedAt   DateTime? // When processing started
 *   completedAt DateTime? // When finished (success or failure)
 *   createdAt   DateTime  @default(now())
 * }
 * ```
 *
 * RETRY STRATEGY:
 * ---------------
 * Uses **Exponential Backoff** for retries:
 * - Attempt 1 fails ‚Üí Retry after 2 minutes (2^1 = 2)
 * - Attempt 2 fails ‚Üí Retry after 4 minutes (2^2 = 4)
 * - Attempt 3 fails ‚Üí Retry after 8 minutes (2^3 = 8)
 * - After 3 attempts ‚Üí Mark as permanently failed
 *
 * Why exponential backoff?
 * - Gives transient issues time to resolve (e.g., database deadlock)
 * - Prevents hammering the database immediately after failure
 * - Common pattern in distributed systems
 *
 * BULK OPTIMIZATION:
 * ------------------
 * Transfer processing uses bulk operations to dramatically improve performance:
 *
 * **Before (Sequential)**: 100 items √ó 500ms per item = 50 seconds
 * **After (Bulk)**: 100 items √∑ 30 per batch √ó 2s per batch = 7 seconds
 *
 * Bulk processing techniques:
 * 1. Process items in batches of 30 (configurable BATCH_SIZE)
 * 2. Use single bulkUpdateStock() call per batch (not 30 separate calls)
 * 3. Auto-verify items with updateMany (not individual updates)
 * 4. Update receivedQuantity in groups by value (reduces queries)
 * 5. Single transaction per batch (reduces commit overhead)
 *
 * TRANSACTION SAFETY:
 * -------------------
 * Each batch is wrapped in a Prisma transaction:
 * - All items in batch succeed together OR all fail together
 * - Prevents partial inventory updates (data integrity)
 * - Timeout: 180 seconds per batch (6 seconds per item √ó 30)
 * - MaxWait: 20 seconds for lock acquisition
 *
 * If batch fails halfway:
 * - Transaction rolls back (no partial updates)
 * - Job marked for retry with exponential backoff
 * - Next attempt processes from beginning (idempotent)
 *
 * COMMON USE CASES:
 * -----------------
 *
 * 1. **Create Transfer Send Job** (API Route)
 * ```typescript
 * import { prisma } from '@/lib/prisma'
 *
 * // After transfer request is approved
 * const job = await prisma.job.create({
 *   data: {
 *     businessId: transfer.businessId,
 *     userId: session.user.id,
 *     type: 'transfer_send',
 *     payload: {
 *       transferId: transfer.id,
 *       notes: 'Approved by manager'
 *     },
 *     total: transfer.items.length,  // For progress tracking
 *     maxAttempts: 3
 *   }
 * })
 *
 * return { message: 'Processing in background', jobId: job.id }
 * ```
 *
 * 2. **Process Job** (Worker or CLI)
 * ```typescript
 * import { processJob } from '@/lib/job-processor'
 *
 * // Get pending jobs
 * const pendingJobs = await prisma.job.findMany({
 *   where: {
 *     status: 'pending',
 *     OR: [
 *       { nextRetryAt: null },           // Never attempted
 *       { nextRetryAt: { lte: new Date() }}  // Retry time reached
 *     ]
 *   },
 *   take: 10  // Process 10 jobs at a time
 * })
 *
 * // Process each job
 * for (const job of pendingJobs) {
 *   await processJob(job)
 * }
 * ```
 *
 * 3. **Check Job Status** (Frontend)
 * ```typescript
 * // Poll job status every 2 seconds
 * const checkStatus = async (jobId: number) => {
 *   const response = await fetch(`/api/jobs/${jobId}`)
 *   const job = await response.json()
 *
 *   if (job.status === 'completed') {
 *     alert('Transfer processed successfully!')
 *   } else if (job.status === 'failed') {
 *     alert(`Transfer failed: ${job.error}`)
 *   } else if (job.status === 'processing') {
 *     console.log(`Progress: ${job.progress}/${job.total} items`)
 *     // Continue polling...
 *   }
 * }
 * ```
 *
 * 4. **Manual Job Creation** (Admin Tools)
 * ```typescript
 * // Reprocess a failed job manually
 * await prisma.job.update({
 *   where: { id: failedJobId },
 *   data: {
 *     status: 'pending',
 *     attempts: 0,           // Reset attempts
 *     error: null,           // Clear error
 *     nextRetryAt: null      // Process immediately
 *   }
 * })
 * ```
 *
 * WORKER DEPLOYMENT:
 * ------------------
 * Job workers can run in multiple ways:
 *
 * **1. CLI Worker** (Development):
 * ```bash
 * npm run worker  # Runs src/scripts/job-worker.ts
 * # Polls database every 5 seconds for pending jobs
 * ```
 *
 * **2. Scheduled Task** (Production):
 * ```javascript
 * // Using node-cron in Next.js API route
 * // Run every 30 seconds: '* / 30 * * * * *' (remove spaces)
 * cron.schedule('* / 30 * * * * *', async () => {
 *   await processPendingJobs()
 * })
 * ```
 *
 * **3. Background Job Queue** (Production - Recommended):
 * ```javascript
 * // Using BullMQ or similar
 * import Queue from 'bull'
 * const jobQueue = new Queue('pos-jobs', 'redis://localhost')
 *
 * jobQueue.process('transfer_send', async (job) => {
 *   await processJob(job.data)
 * })
 * ```
 *
 * TYPESCRIPT PATTERNS:
 * --------------------
 *
 * **Switch Statement for Job Routing**:
 * ```typescript
 * switch (job.type) {
 *   case 'transfer_send': return await processTransferSend(job)
 *   case 'transfer_complete': return await processTransferComplete(job)
 *   default: throw new Error(`Unknown job type`)
 * }
 * ```
 * - Routes to appropriate processor based on job type
 * - Centralized error handling for unknown types
 * - Easy to add new job types
 *
 * **Exponential Backoff Calculation**:
 * ```typescript
 * const retryDelay = Math.pow(2, job.attempts) * 60 * 1000
 * ```
 * - Math.pow(2, n) = 2^n (2, 4, 8, 16, ...)
 * - Multiply by 60,000ms = minutes
 * - Example: attempts=2 ‚Üí 2^2 = 4 ‚Üí 4 minutes
 *
 * **Batch Processing Pattern**:
 * ```typescript
 * for (let i = 0; i < items.length; i += BATCH_SIZE) {
 *   const batch = items.slice(i, i + BATCH_SIZE)
 *   await processBatch(batch)
 * }
 * ```
 * - Process items in chunks (not all at once)
 * - Prevents memory overflow for large datasets
 * - Provides incremental progress updates
 *
 * PRISMA PATTERNS:
 * ----------------
 *
 * **Transaction with Timeout**:
 * ```typescript
 * await prisma.$transaction(async (tx) => {
 *   // All operations here are atomic
 * }, {
 *   timeout: 180000,  // 3 minutes
 *   maxWait: 20000    // 20 seconds to acquire lock
 * })
 * ```
 * - Ensures data consistency (all or nothing)
 * - Timeout prevents hanging transactions
 * - MaxWait prevents indefinite lock waits
 *
 * **UpdateMany for Bulk Updates**:
 * ```typescript
 * await tx.stockTransferItem.updateMany({
 *   where: { id: { in: itemIds }},
 *   data: { verified: true, verifiedAt: new Date() }
 * })
 * ```
 * - Updates multiple records in single query (faster)
 * - Cannot update with different values per record
 * - For different values, group by value and run updateMany per group
 *
 * PERFORMANCE NOTES:
 * ------------------
 * - Batch size 30 is optimal for balance between speed and memory
 * - Larger batches = fewer transactions but longer lock time
 * - Smaller batches = more transactions but shorter lock time
 * - Monitor job completion time and adjust BATCH_SIZE if needed
 * - Database connection pooling is critical for concurrent jobs
 *
 * IMPORTANT NOTES:
 * ----------------
 * - Jobs are NOT deleted after completion (kept for audit trail)
 * - Clean up old completed jobs periodically (e.g., delete > 30 days old)
 * - Job processor is idempotent (safe to retry from beginning)
 * - Progress tracking shows partial completion for user feedback
 * - Failed jobs need manual review (check error message)
 * - Worker crash doesn't lose jobs (resume from database state)
 * - Consider distributed locking for multiple workers (prevent duplicate processing)
 * - Monitor job queue depth (too many pending = need more workers)
 */

import { PrismaClient } from '@prisma/client'
import { transferStockOut, addStock, bulkUpdateStock, StockTransactionType } from '@/lib/stockOperations'

const prisma = new PrismaClient()

/**
 * Sleep utility
 *
 * Returns a Promise that resolves after specified milliseconds.
 * Useful for rate limiting or delays in processing.
 *
 * @param ms - Milliseconds to sleep
 * @returns Promise that resolves after delay
 */
const sleep = (ms: number) => new Promise((resolve) => setTimeout(resolve, ms))

// Process a single job
export async function processJob(job: any) {
  const startTime = Date.now()

  try {
    console.log(`\n[Job ${job.id}] Processing job type: ${job.type}`)

    // Mark as processing
    await prisma.job.update({
      where: { id: job.id },
      data: {
        status: 'processing',
        startedAt: new Date(),
        attempts: job.attempts + 1,
      },
    })

    let result: any

    // Route to appropriate processor
    switch (job.type) {
      case 'transfer_send':
        result = await processTransferSend(job)
        break
      case 'transfer_complete':
        result = await processTransferComplete(job)
        break
      case 'sale_create':
        result = await processSaleCreate(job)
        break
      case 'purchase_approve':
        result = await processPurchaseApprove(job)
        break
      default:
        throw new Error(`Unknown job type: ${job.type}`)
    }

    // Mark as completed
    const duration = Date.now() - startTime
    await prisma.job.update({
      where: { id: job.id },
      data: {
        status: 'completed',
        progress: job.total,
        result: result as any,
        completedAt: new Date(),
      },
    })

    console.log(`[Job ${job.id}] ‚úÖ Completed in ${duration}ms`)
  } catch (error: any) {
    console.error(`[Job ${job.id}] ‚ùå Failed:`, error.message)

    // Check if should retry
    const shouldRetry = job.attempts < job.maxAttempts

    if (shouldRetry) {
      // Schedule retry (exponential backoff)
      const retryDelay = Math.pow(2, job.attempts) * 60 * 1000 // 2^n minutes
      const nextRetryAt = new Date(Date.now() + retryDelay)

      await prisma.job.update({
        where: { id: job.id },
        data: {
          status: 'pending', // Back to pending for retry
          error: error.message,
          nextRetryAt,
        },
      })

      console.log(
        `[Job ${job.id}] ‚è≥ Scheduled retry ${job.attempts + 1}/${job.maxAttempts} at ${nextRetryAt.toISOString()}`
      )
    } else {
      // Max attempts reached, mark as failed
      await prisma.job.update({
        where: { id: job.id },
        data: {
          status: 'failed',
          error: error.message,
          completedAt: new Date(),
        },
      })

      console.log(`[Job ${job.id}] üíÄ Failed permanently after ${job.maxAttempts} attempts`)
    }
  }
}

// ============================================
// JOB PROCESSORS
// ============================================

async function processTransferSend(job: any) {
  const payload = job.payload as { transferId: number; notes?: string }
  const { transferId, notes } = payload

  console.log(`[Job ${job.id}] Processing transfer send for transfer #${transferId}`)

  // Get transfer
  const transfer = await prisma.stockTransfer.findUnique({
    where: { id: transferId },
    include: { items: true },
  })

  if (!transfer) {
    throw new Error(`Transfer ${transferId} not found`)
  }

  // Get user info
  const user = await prisma.user.findUnique({
    where: { id: job.userId },
    select: { username: true, firstName: true, lastName: true },
  })

  const userDisplayName =
    [user?.firstName, user?.lastName].filter(Boolean).join(' ') ||
    user?.username ||
    `User#${job.userId}`

  // Process items in batches
  const BATCH_SIZE = 30 // Increased from 10 to reduce transaction overhead
  let processedCount = 0

  for (let i = 0; i < transfer.items.length; i += BATCH_SIZE) {
    const batch = transfer.items.slice(i, i + BATCH_SIZE)

    await prisma.$transaction(
      async (tx) => {
        // BULK OPTIMIZATION: Process all items in batch with single function call
        // Prepare bulk update parameters
        const bulkItems = batch.map((item) => ({
          businessId: job.businessId,
          productId: item.productId,
          productVariationId: item.productVariationId,
          locationId: transfer.fromLocationId,
          quantity: -Math.abs(parseFloat(item.quantity.toString())), // Negative for stock out
          type: StockTransactionType.TRANSFER_OUT,
          referenceType: 'transfer' as const,
          referenceId: transferId,
          userId: job.userId,
          notes: notes || `Transfer ${transfer.transferNumber} sent`,
          userDisplayName,
          allowNegative: true, // Allow negative for async transfers (stock may have changed since creation)
          tx,
        }))

        // Call bulk function - processes all items in single server call
        const results = await bulkUpdateStock(bulkItems)

        // Check for failures
        const failures = results.filter((r) => !r.success)
        if (failures.length > 0) {
          const firstFailure = failures[0]
          console.error(
            `[Job ${job.id}] Bulk transfer send failed:`,
            firstFailure.error
          )
          throw new Error(`Bulk update failed: ${firstFailure.error}`)
        }

        processedCount += batch.length

        // Update job progress once per batch
        await tx.job.update({
          where: { id: job.id },
          data: { progress: processedCount },
        })
      },
      {
        timeout: 180000, // 180s per batch (6s per item for 30 items)
        maxWait: 20000, // Increased wait time for lock acquisition
      }
    )

    console.log(
      `[Job ${job.id}] Progress: ${processedCount}/${transfer.items.length} items`
    )
  }

  // Update transfer status
  await prisma.stockTransfer.update({
    where: { id: transferId },
    data: {
      status: 'in_transit',
      stockDeducted: true,
      sentBy: job.userId,
      sentAt: new Date(),
    },
  })

  return {
    transferId,
    transferNumber: transfer.transferNumber,
    itemsProcessed: processedCount,
  }
}

async function processTransferComplete(job: any) {
  const payload = job.payload as { transferId: number; notes?: string }
  const { transferId, notes } = payload

  console.log(`[Job ${job.id}] Processing transfer complete for transfer #${transferId}`)

  // Get transfer
  const transfer = await prisma.stockTransfer.findUnique({
    where: { id: transferId },
    include: { items: true },
  })

  if (!transfer) {
    throw new Error(`Transfer ${transferId} not found`)
  }

  // Get user info
  const user = await prisma.user.findUnique({
    where: { id: job.userId },
    select: { username: true, firstName: true, lastName: true },
  })

  const userDisplayName =
    [user?.firstName, user?.lastName].filter(Boolean).join(' ') ||
    user?.username ||
    `User#${job.userId}`

  // Process items in batches
  const BATCH_SIZE = 30 // Increased from 10 to reduce transaction overhead
  let processedCount = 0

  for (let i = 0; i < transfer.items.length; i += BATCH_SIZE) {
    const batch = transfer.items.slice(i, i + BATCH_SIZE)

    await prisma.$transaction(
      async (tx) => {
        // BULK OPTIMIZATION STEP 1: Auto-verify all unverified items in this batch (single query)
        const batchItemIds = batch.map(item => item.id)
        const unverifiedInBatch = batch.filter(item => !item.verified)

        if (unverifiedInBatch.length > 0) {
          console.log(`[Job ${job.id}] Auto-verifying ${unverifiedInBatch.length} items in batch`)

          await tx.stockTransferItem.updateMany({
            where: {
              id: { in: unverifiedInBatch.map(item => item.id) },
              verified: false, // Only update unverified items
            },
            data: {
              verified: true,
              verifiedBy: job.userId,
              verifiedAt: new Date(),
            },
          })

          // BULK OPTIMIZATION 3: Update receivedQuantity in batch (saves ~4 seconds for 11 items)
          const itemsNeedingReceivedQty = unverifiedInBatch.filter(
            item => !item.receivedQuantity || item.receivedQuantity.toString() === '0'
          )

          if (itemsNeedingReceivedQty.length > 0) {
            // Update all items where receivedQuantity needs to be set to quantity
            // Note: Prisma doesn't support CASE WHEN in updateMany, so we batch by quantity
            const quantityGroups = new Map<string, number[]>()

            for (const item of itemsNeedingReceivedQty) {
              const qtyKey = item.quantity.toString()
              if (!quantityGroups.has(qtyKey)) {
                quantityGroups.set(qtyKey, [])
              }
              quantityGroups.get(qtyKey)!.push(item.id)
            }

            // Execute one updateMany per unique quantity value
            for (const [quantity, itemIds] of quantityGroups) {
              await tx.stockTransferItem.updateMany({
                where: { id: { in: itemIds } },
                data: { receivedQuantity: parseFloat(quantity) },
              })
            }
          }
        }

        // BULK OPTIMIZATION STEP 2: Process all inventory additions in single function call
        // Prepare bulk update parameters
        const bulkItems = batch.map((item) => {
          // CRITICAL FIX: Properly handle NULL vs 0 vs missing receivedQuantity
          const receivedQtyValue = item.receivedQuantity != null
            ? parseFloat(item.receivedQuantity.toString())
            : null

          const receivedQty = (receivedQtyValue != null && receivedQtyValue > 0)
            ? receivedQtyValue
            : parseFloat(item.quantity.toString())

          console.log(`[Job Processor Transfer] Item ${item.id}: receivedQuantity=${item.receivedQuantity}, calculated receivedQty=${receivedQty}, original quantity=${item.quantity}`)

          return {
            businessId: job.businessId,
            productId: item.productId,
            productVariationId: item.productVariationId,
            locationId: transfer.toLocationId,
            quantity: receivedQty, // Positive for stock in
            type: StockTransactionType.TRANSFER_IN,
            referenceType: 'stock_transfer' as const,
            referenceId: transferId,
            referenceNumber: transfer.transferNumber,
            userId: job.userId,
            notes: `Transfer ${transfer.transferNumber} received`,
            userDisplayName,
            tx,
          }
        })

        // Call bulk function - processes all items in single server call
        const results = await bulkUpdateStock(bulkItems)

        // Check for failures
        const failures = results.filter((r) => !r.success)
        if (failures.length > 0) {
          const firstFailure = failures[0]
          console.error(
            `[Job ${job.id}] Bulk transfer receive failed:`,
            firstFailure.error
          )
          throw new Error(`Bulk update failed: ${firstFailure.error}`)
        }

        processedCount += batch.length

        // Update job progress once per batch
        await tx.job.update({
          where: { id: job.id },
          data: { progress: processedCount },
        })
      },
      {
        timeout: 180000, // 180s per batch (6s per item for 30 items)
        maxWait: 20000, // Increased wait time for lock acquisition
      }
    )

    console.log(
      `[Job ${job.id}] Progress: ${processedCount}/${transfer.items.length} items`
    )
  }

  // Update transfer status
  await prisma.stockTransfer.update({
    where: { id: transferId },
    data: {
      status: 'completed',
      completedBy: job.userId,
      completedAt: new Date(),
      verifiedBy: job.userId,
      verifiedAt: new Date(),
      receivedAt: new Date(),
    },
  })

  return {
    transferId,
    transferNumber: transfer.transferNumber,
    itemsProcessed: processedCount,
  }
}

async function processSaleCreate(job: any) {
  // TODO: Implement sale creation in background
  throw new Error('Sale creation not yet implemented in job worker')
}

async function processPurchaseApprove(job: any) {
  // TODO: Implement purchase approval in background
  throw new Error('Purchase approval not yet implemented in job worker')
}

export { processTransferSend, processTransferComplete }
